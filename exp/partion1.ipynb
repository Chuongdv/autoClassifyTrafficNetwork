{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:29:14 INFO     Reading data file '/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/Flow_Duration.tsv' as 'real location' with error 0.01\n",
      "2020-04-26 21:29:14 INFO     Detected encoding: ascii\n",
      "2020-04-26 21:29:14 INFO     Found 4916 rows and 2 columns\n",
      "2020-04-26 21:29:14 DEBUG    Checking column names\n",
      "2020-04-26 21:29:14 DEBUG    Index name 'index'\n",
      "2020-04-26 21:29:14 DEBUG    Column name 'Flow_Duration'\n",
      "2020-04-26 21:29:14 INFO     Checking data format\n",
      "2020-04-26 21:29:14 INFO     Column 'Flow_Duration'\n",
      "2020-04-26 21:29:14 INFO     count    4.916000e+03\n",
      "2020-04-26 21:29:14 INFO     mean     2.700050e+07\n",
      "2020-04-26 21:29:14 INFO     std      4.043878e+07\n",
      "2020-04-26 21:29:14 INFO     min      1.000000e+00\n",
      "2020-04-26 21:29:14 INFO     50%      1.005040e+06\n",
      "2020-04-26 21:29:14 INFO     max      1.200000e+08\n",
      "2020-04-26 21:29:14 INFO     ---\n",
      "2020-04-26 21:29:14 INFO     Final dataframe has 4916 lines and 2 columns\n",
      "2020-04-26 21:29:14 INFO     Searching for missing values\n",
      "2020-04-26 21:29:14 INFO     No missing values found\n",
      "2020-04-26 21:29:14 INFO     Writing autoclass.db2 file\n",
      "2020-04-26 21:29:14 INFO     If any, missing values will be encoded as '?'\n",
      "2020-04-26 21:29:14 DEBUG    Writing autoclass.tsv file [for later use]\n",
      "2020-04-26 21:29:14 INFO     Writing .hd2 file\n",
      "2020-04-26 21:29:14 INFO     Writing .model file\n",
      "2020-04-26 21:29:14 INFO     Writing .s-params file\n",
      "2020-04-26 21:29:14 INFO     Writing .r-params file\n",
      "2020-04-26 21:29:14 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 21:29:14 INFO     Writing run file\n",
      "2020-04-26 21:29:14 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 21:29:15 INFO     AutoClass C version: AUTOCLASS C (version 3.3.6unx)\n",
      "2020-04-26 21:29:15 INFO     Running clustering...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1342 sec."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:51:38 INFO     Extracting autoclass results\n",
      "2020-04-26 21:51:38 INFO     Found 4916 cases classified in 68 classes\n",
      "2020-04-26 21:51:42 INFO     Aggregating input data\n",
      "2020-04-26 21:51:42 INFO     Writing classes + probabilities .tsv file\n",
      "2020-04-26 21:51:43 INFO     Reading data file '/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/Total_Fwd_Packets.tsv' as 'real location' with error 0.01\n",
      "2020-04-26 21:51:43 INFO     Detected encoding: ascii\n",
      "2020-04-26 21:51:43 INFO     Found 4916 rows and 2 columns\n",
      "2020-04-26 21:51:43 DEBUG    Checking column names\n",
      "2020-04-26 21:51:43 DEBUG    Index name 'index'\n",
      "2020-04-26 21:51:43 DEBUG    Column name 'Total_Fwd_Packets'\n",
      "2020-04-26 21:51:43 INFO     Checking data format\n",
      "2020-04-26 21:51:43 INFO     Column 'Total_Fwd_Packets'\n",
      "2020-04-26 21:51:43 INFO     count      4916.000000\n",
      "2020-04-26 21:51:43 INFO     mean        175.268511\n",
      "2020-04-26 21:51:43 INFO     std        3435.497983\n",
      "2020-04-26 21:51:43 INFO     min           1.000000\n",
      "2020-04-26 21:51:43 INFO     50%           6.000000\n",
      "2020-04-26 21:51:43 INFO     max      233033.000000\n",
      "2020-04-26 21:51:43 INFO     ---\n",
      "2020-04-26 21:51:43 INFO     Final dataframe has 4916 lines and 2 columns\n",
      "2020-04-26 21:51:43 INFO     Searching for missing values\n",
      "2020-04-26 21:51:43 INFO     No missing values found\n",
      "2020-04-26 21:51:43 INFO     Writing autoclass.db2 file\n",
      "2020-04-26 21:51:43 INFO     If any, missing values will be encoded as '?'\n",
      "2020-04-26 21:51:43 DEBUG    Writing autoclass.tsv file [for later use]\n",
      "2020-04-26 21:51:43 INFO     Writing .hd2 file\n",
      "2020-04-26 21:51:43 INFO     Writing .model file\n",
      "2020-04-26 21:51:43 INFO     Writing .s-params file\n",
      "2020-04-26 21:51:43 INFO     Writing .r-params file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1751412429378531, 0.08273381294964029, 0.05909090909090909, 0.16363636363636364, 0.15384615384615385, 0.1744186046511628, 0.08695652173913043, 0.07777777777777778, 0.09815950920245399, 0.1875, 0.06504065040650407, 0.08943089430894309, 0.11538461538461539, 0.07407407407407407, 0.22727272727272727, 0.39097744360902253, 0.27049180327868855, 0.10185185185185185, 0.06422018348623854, 0.20192307692307693, 0.08888888888888889, 0.21686746987951808, 0.07042253521126761, 0.18309859154929578, 0.7659574468085106, 0.13253012048192772, 0.07575757575757576, 0.14705882352941177, 0.16666666666666666, 0.1111111111111111, 0.1016949152542373, 0.1111111111111111, 0.15942028985507245, 0.16923076923076924, 0.11764705882352941, 0.4883720930232558, 0.25, 0.08108108108108109, 0.09302325581395349, 0.5853658536585366, 0.18421052631578946, 0.08108108108108109, 0.9032258064516129, 0.14285714285714285, 0.08823529411764706, 0.09375, 0.08695652173913043, 0.08695652173913043, 0.10526315789473684, 0.25, 0.7777777777777778, 0.631578947368421, 0.16666666666666666, 0.35, 0.5, 0.11764705882352941, 0.2, 0.23076923076923078, 0.9166666666666666, 0.2222222222222222, 0.8, 0.2222222222222222, 0.2, 0.125, 0.16666666666666666, 0.5, 0.5, 0.5]\n",
      "['NTP', 'IP_ICMP', 'HTTP', 'NTP', 'SSL_NO_CERT', 'FTP_DATA', 'GMAIL', 'CLOUDFLARE', 'MS_ONE_DRIVE', 'DROPBOX', 'SKYPE', 'CLOUDFLARE', 'SPOTIFY', 'MICROSOFT', 'EDONKEY', 'CONTENT_FLASH', 'DNS', 'CONTENT_FLASH', 'TOR', 'AMAZON', 'HTTP_PROXY', 'SPOTIFY', 'MQTT', 'WINDOWS_UPDATE', 'TEAMVIEWER', 'SSL', 'EASYTAXI', 'TOR', 'WAZE', 'TWITTER', 'UPNP', 'FACEBOOK', 'DEEZER', 'TELEGRAM', 'APPLE_ICLOUD', 'DEEZER', 'OFFICE_365', 'TOR', 'EBAY', 'INSTAGRAM', 'CONTENT_FLASH', 'GOOGLE', 'SSH', 'FACEBOOK', 'FTP_DATA', 'MSN', 'FACEBOOK', 'WIKIPEDIA', 'SPOTIFY', 'EBAY', 'CLOUDFLARE', 'WAZE', 'DROPBOX', 'EDONKEY', 'TEAMVIEWER', 'MS_ONE_DRIVE', 'GOOGLE_MAPS', 'MQTT', 'WAZE', 'FTP_DATA', 'WAZE', 'EASYTAXI', 'YAHOO', 'TOR', 'UBUNTUONE', 'FACEBOOK', 'LASTFM', 'HTTP_CONNECT']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "0.23713216743444962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:51:43 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 21:51:43 INFO     Writing run file\n",
      "2020-04-26 21:51:43 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 21:51:43 INFO     AutoClass C version: AUTOCLASS C (version 3.3.6unx)\n",
      "2020-04-26 21:51:43 INFO     Running clustering...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 450 sec."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:59:14 INFO     Extracting autoclass results\n",
      "2020-04-26 21:59:14 INFO     Found 4916 cases classified in 45 classes\n",
      "2020-04-26 21:59:16 INFO     Aggregating input data\n",
      "2020-04-26 21:59:16 INFO     Writing classes + probabilities .tsv file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.044101433296582136, 0.0801781737193764, 0.15151515151515152, 0.09004739336492891, 0.08994708994708994, 0.10160427807486631, 0.1411192214111922, 0.1392857142857143, 0.06557377049180328, 0.04918032786885246, 0.12037037037037036, 0.47572815533980584, 0.21649484536082475, 0.10344827586206896, 0.13953488372093023, 0.13580246913580246, 0.125, 0.4473684210526316, 0.06779661016949153, 0.14285714285714285, 0.32558139534883723, 0.15428571428571428, 0.09803921568627451, 0.12, 0.08163265306122448, 0.11904761904761904, 0.3333333333333333, 0.15384615384615385, 0.11428571428571428, 0.14285714285714285, 0.21875, 0.1111111111111111, 0.17857142857142858, 0.25925925925925924, 0.125, 0.15, 0.5263157894736842, 0.15, 0.4375, 0.09090909090909091, 0.1, 0.3333333333333333, 0.16666666666666666, 0.2727272727272727, 0.4]\n",
      "['CLOUDFLARE', 'FACEBOOK', 'TEAMVIEWER', 'CONTENT_FLASH', 'OFFICE_365', 'MQTT', 'NTP', 'NTP', 'MICROSOFT', 'INSTAGRAM', 'TEAMVIEWER', 'DNS', 'WAZE', 'SSL_NO_CERT', 'SSL_NO_CERT', 'SSL_NO_CERT', 'APPLE_ICLOUD', 'EDONKEY', 'SSH', 'SSH', 'DNS', 'CONTENT_FLASH', 'TOR', 'SSH', 'GMAIL', 'YOUTUBE', 'CITRIX_ONLINE', 'CITRIX_ONLINE', 'GOOGLE_MAPS', 'FTP_CONTROL', 'WAZE', 'APPLE_ICLOUD', 'OFFICE_365', 'WINDOWS_UPDATE', 'MICROSOFT', 'WIKIPEDIA', 'SSH', 'GOOGLE_MAPS', 'OPENSIGNAL', 'TOR', 'YAHOO', 'FTP_CONTROL', 'GMAIL', 'CITRIX_ONLINE', 'WINDOWS_UPDATE']\n",
      "[1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54]\n",
      "0.17977792492552191\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0667e7e25f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mafterall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mround1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafterall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mround1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/chuongdv/Documents/SourceCode/MachineLearning/resl.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import autoclasswrapper as wrapper\n",
    "import os \n",
    "\n",
    "afterall = {}\n",
    "subfeatures = ['Flow_Duration', 'Total_Fwd_Packets']\n",
    "os.environ['PATH'] += \":/home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c\"\n",
    "!touch /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "!echo \"xref_class_report_att_list = 0, 1 \\nreport_mode = \\\"data\\\" \\ncomment_data_headers_p = true \" >> /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "for feature in subfeatures:\n",
    "    runtimeDir = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/\" + feature\n",
    "    if not Path(runtimeDir).exists():\n",
    "        os.mkdir(runtimeDir)\n",
    "    os.chdir(runtimeDir)\n",
    "    \n",
    "            # Create object to prepare dataset.\n",
    "    clust = wrapper.Input()\n",
    "\n",
    "    # Load datasets from tsv files.\n",
    "    pathData = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/\" + feature + \".tsv\"\n",
    "    clust.add_input_data(pathData, \"real location\")\n",
    "    \n",
    "    # Prepare input data:\n",
    "    # - create a final dataframe\n",
    "    # - merge datasets if multiple inputs\n",
    "    clust.prepare_input_data()\n",
    "\n",
    "    # Create files needed by AutoClass.\n",
    "    clust.create_db2_file()\n",
    "    clust.create_hd2_file()\n",
    "    clust.create_model_file()\n",
    "    clust.create_sparams_file(max_duration = 0)\n",
    "    clust.create_rparams_file()\n",
    "    !rm autoclass.r-params\n",
    "    !cp /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params .\n",
    "    \n",
    "    !rm -f autoclass-run-* *.results-bin\n",
    "\n",
    "\n",
    "    # Search autoclass in path.\n",
    "    wrapper.search_autoclass_in_path()\n",
    "\n",
    "    # Create object to run AutoClass.\n",
    "    run = wrapper.Run()\n",
    "\n",
    "    # Prepare run script.\n",
    "    run.create_run_file()\n",
    "\n",
    "    # Run AutoClass.\n",
    "    run.run()\n",
    "        \n",
    "    timer = 0\n",
    "    step = 2\n",
    "    while not Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        timer += step\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(f\"Time: {timer} sec.\")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(step)\n",
    "        if Path(\"autoclass-run-failure\").exists():\n",
    "            print(\"error\")\n",
    "            break\n",
    "            \n",
    "    if Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        results = wrapper.Output()\n",
    "        results.extract_results()\n",
    "        results.aggregate_input_data()\n",
    "#         results.write_cdt()\n",
    "#         results.write_cdt(with_proba=True)\n",
    "#         results.write_class_stats()\n",
    "#         results.write_dendrogram()\n",
    "        result = pd.read_csv(runtimeDir + '/autoclass_out.tsv', encoding=\"utf-8\", header=0, sep='\\t', index_col=0)\n",
    "        label =  pd.read_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/ProtocolName.tsv', encoding='utf-8', header=0, sep='\\t', index_col=0)\n",
    "\n",
    "        label['cluster'] = result['main-class']\n",
    "        label.to_csv('app.csv', index = True, header=True)\n",
    "\n",
    "\n",
    "        listH = []\n",
    "        listApp = []\n",
    "        listCluster = []\n",
    "        def fun(x):\n",
    "            listCluster.append(x['cluster'].values[0])\n",
    "            listH.append(x['ProtocolName'].value_counts().max()/x.shape[0])\n",
    "            listApp.append(x['ProtocolName'].value_counts().idxmax())\n",
    "\n",
    "\n",
    "        label.groupby('cluster').apply(fun)\n",
    "\n",
    "        H = sum(listH)/len(listH)\n",
    "        print(listH)\n",
    "        print(listApp)\n",
    "        print(listCluster)\n",
    "        print(H)\n",
    "\n",
    "        dict = {'Cluster': listCluster, 'App': listApp, 'H': listH}\n",
    "\n",
    "        saveResult = pd.DataFrame(dict)\n",
    "\n",
    "        saveResult.to_csv(runtimeDir + '/resultCal.csv', index = True, header=True)\n",
    "        \n",
    "        afterall.update({feature:H})\n",
    "        \n",
    "round1 = pd.DataFrame(afterall)\n",
    "round1.to_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/resl.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11434511434511435, 0.21212121212121213, 0.064343163538874, 0.2364341085271318, 0.06796116504854369, 0.32894736842105265, 0.1572052401746725, 0.19166666666666668, 0.13194444444444445, 0.08396946564885496, 0.22388059701492538, 0.09243697478991597, 0.11811023622047244, 0.272, 0.0673076923076923, 0.0784313725490196, 0.06422018348623854, 0.0967741935483871, 0.14432989690721648, 0.12790697674418605, 0.18309859154929578, 0.21052631578947367, 0.0958904109589041, 0.08823529411764706, 0.15492957746478872, 0.1643835616438356, 0.17543859649122806, 0.1016949152542373, 0.15942028985507245, 0.1038961038961039, 0.11627906976744186, 0.4883720930232558, 0.10526315789473684, 0.25, 0.5714285714285714, 0.09523809523809523, 0.27586206896551724, 0.13333333333333333, 0.2903225806451613, 0.5, 0.5909090909090909, 0.16, 0.3076923076923077, 0.08695652173913043, 0.7777777777777778, 0.631578947368421, 0.125, 1.0, 0.3076923076923077, 0.125, 0.9230769230769231, 0.16666666666666666, 0.2857142857142857, 0.5, 0.4, 0.3333333333333333, 0.3333333333333333]\n",
      "['IP_ICMP', 'NTP', 'HTTP', 'CONTENT_FLASH', 'MS_ONE_DRIVE', 'TEAMVIEWER', 'FTP_DATA', 'DROPBOX', 'UBUNTUONE', 'TELEGRAM', 'EDONKEY', 'CLOUDFLARE', 'SPOTIFY', 'DNS', 'SKYPE', 'HTTP_PROXY', 'INSTAGRAM', 'FACEBOOK', 'HTTP_DOWNLOAD', 'SSL', 'WINDOWS_UPDATE', 'AMAZON', 'TWITTER', 'MICROSOFT', 'TOR', 'WAZE', 'SPOTIFY', 'YAHOO', 'DEEZER', 'MQTT', 'DROPBOX', 'DEEZER', 'MQTT', 'OFFICE_365', 'INSTAGRAM', 'EBAY', 'SSL_NO_CERT', 'FACEBOOK', 'TEAMVIEWER', 'WAZE', 'SSH', 'GMAIL', 'SPOTIFY', 'HTTP', 'CLOUDFLARE', 'WAZE', 'EBAY', 'SSH', 'EBAY', 'MS_ONE_DRIVE', 'WAZE', 'EASYTAXI', 'SKYPE', 'FACEBOOK', 'WHATSAPP', 'HTTP_CONNECT', 'TWITTER']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
      "0.24899438938815618\n"
     ]
    }
   ],
   "source": [
    "        result = pd.read_csv(runtimeDir + '/autoclass_out.tsv', encoding=\"utf-8\", header=0, sep='\\t', index_col=0)\n",
    "        label =  pd.read_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/ProtocolName.tsv', encoding='utf-8', header=0, sep='\\t', index_col=0)\n",
    "\n",
    "        label['cluster'] = result['main-class']\n",
    "        label.to_csv('app.csv', index = True, header=True)\n",
    "\n",
    "\n",
    "        listH = []\n",
    "        listApp = []\n",
    "        listCluster = []\n",
    "        def fun(x):\n",
    "            listCluster.append(x['cluster'].values[0])\n",
    "            listH.append(x['ProtocolName'].value_counts().max()/x.shape[0])\n",
    "            listApp.append(x['ProtocolName'].value_counts().idxmax())\n",
    "\n",
    "\n",
    "        label.groupby('cluster').apply(fun)\n",
    "\n",
    "        H = sum(listH)/len(listH)\n",
    "        print(listH)\n",
    "        print(listApp)\n",
    "        print(listCluster)\n",
    "        print(H)\n",
    "\n",
    "        dict = {'Cluster': listCluster, 'App': listApp, 'H': listH}\n",
    "\n",
    "        saveResult = pd.DataFrame(dict)\n",
    "\n",
    "        saveResult.to_csv(runtimeDir + 'resultCal.csv', index = True, header=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
