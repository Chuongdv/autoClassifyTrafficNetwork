{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import autoclasswrapper as wrapper\n",
    "import os \n",
    "\n",
    "afterall = {}\n",
    "subfeatures = ['P0', 'P1', 'P2', 'P3', 'P4']\n",
    "os.environ['PATH'] += \":/home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c\"\n",
    "#!touch /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "#!echo \"xref_class_report_att_list = 0, 1 \\nreport_mode = \\\"data\\\" \\ncomment_data_headers_p = true \" >> /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "for feature in subfeatures:\n",
    "    runtimeDir = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/round1/\" + feature\n",
    "    if not Path(runtimeDir).exists():\n",
    "        os.mkdir(runtimeDir)\n",
    "    os.chdir(runtimeDir)\n",
    "    \n",
    "            # Create object to prepare dataset.\n",
    "    clust = wrapper.Input()\n",
    "\n",
    "    # Load datasets from tsv files.\n",
    "    pathData = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/\" + feature + \".tsv\"\n",
    "    clust.add_input_data(pathData, \"real location\")\n",
    "    #clust.add_input_data(\"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/P2.tsv\", \"real location\")\n",
    "    \n",
    "    # Prepare input data:\n",
    "    # - create a final dataframe\n",
    "    # - merge datasets if multiple inputs\n",
    "    clust.prepare_input_data()\n",
    "\n",
    "    # Create files needed by AutoClass.\n",
    "    clust.create_db2_file()\n",
    "    clust.create_hd2_file()\n",
    "    clust.create_model_file()\n",
    "    clust.create_sparams_file(max_duration = 0)\n",
    "    clust.create_rparams_file()\n",
    "    !rm autoclass.r-params\n",
    "    !cp /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/round1/autoclass.r-params .\n",
    "    \n",
    "    !rm -f autoclass-run-* *.results-bin\n",
    "\n",
    "\n",
    "    # Search autoclass in path.\n",
    "    wrapper.search_autoclass_in_path()\n",
    "\n",
    "    # Create object to run AutoClass.\n",
    "    run = wrapper.Run()\n",
    "\n",
    "    # Prepare run script.\n",
    "    run.create_run_file()\n",
    "\n",
    "    # Run AutoClass.\n",
    "    run.run()\n",
    "        \n",
    "    timer = 0\n",
    "    step = 2\n",
    "    while not Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        timer += step\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(f\"Time: {timer} sec.\")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(step)\n",
    "        if Path(\"autoclass-run-failure\").exists():\n",
    "            print(\"error\")\n",
    "            break\n",
    "            \n",
    "    if Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        results = wrapper.Output()\n",
    "        results.extract_results()\n",
    "        results.aggregate_input_data()\n",
    "#         results.write_cdt()\n",
    "#         results.write_cdt(with_proba=True)\n",
    "#         results.write_class_stats()\n",
    "#         results.write_dendrogram()\n",
    "        result = pd.read_csv(runtimeDir + '/autoclass_out.tsv', encoding=\"utf-8\", header=0, sep='\\t', index_col=0)\n",
    "        label =  pd.read_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/label.tsv', encoding='utf-8', header=0, sep='\\t', index_col=0)\n",
    "\n",
    "        label['cluster'] = result['main-class']\n",
    "        label.to_csv('app.csv', index = True, header=True)\n",
    "\n",
    "\n",
    "        listH = []\n",
    "        listApp = []\n",
    "        listCluster = []\n",
    "        def fun(x):\n",
    "            listCluster.append(x['cluster'].values[0])\n",
    "            listH.append(x['label'].value_counts().max()/x.shape[0])\n",
    "            listApp.append(x['label'].value_counts().idxmax())\n",
    "\n",
    "\n",
    "        label.groupby('cluster').apply(fun)\n",
    "\n",
    "        H = sum(listH)/len(listH)\n",
    "        print(listH)\n",
    "        print(listApp)\n",
    "        print(listCluster)\n",
    "        print(H)\n",
    "\n",
    "        dict = {'Cluster': listCluster, 'App': listApp, 'H': listH}\n",
    "\n",
    "        saveResult = pd.DataFrame(dict)\n",
    "\n",
    "        saveResult.to_csv(runtimeDir + '/resultCal.csv', index = True, header=True)\n",
    "        \n",
    "        afterall.update({feature:H})\n",
    "        \n",
    "round1 = pd.DataFrame(list(afterall.items()), index= range(len(subfeatures)))\n",
    "round1.info()\n",
    "round1.head(1)\n",
    "round1.to_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/round1/H.csv', index = True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
