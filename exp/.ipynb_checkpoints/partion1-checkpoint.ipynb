{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 20:56:30 INFO     Reading data file '/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/Flow_Duration.tsv' as 'real location' with error 0.01\n",
      "2020-04-26 20:56:30 INFO     Detected encoding: ascii\n",
      "2020-04-26 20:56:30 INFO     Found 4916 rows and 2 columns\n",
      "2020-04-26 20:56:30 DEBUG    Checking column names\n",
      "2020-04-26 20:56:30 DEBUG    Index name 'index'\n",
      "2020-04-26 20:56:30 DEBUG    Column name 'Flow_Duration'\n",
      "2020-04-26 20:56:30 INFO     Checking data format\n",
      "2020-04-26 20:56:30 INFO     Column 'Flow_Duration'\n",
      "2020-04-26 20:56:30 INFO     count    4.916000e+03\n",
      "2020-04-26 20:56:30 INFO     mean     2.700050e+07\n",
      "2020-04-26 20:56:30 INFO     std      4.043878e+07\n",
      "2020-04-26 20:56:30 INFO     min      1.000000e+00\n",
      "2020-04-26 20:56:30 INFO     50%      1.005040e+06\n",
      "2020-04-26 20:56:30 INFO     max      1.200000e+08\n",
      "2020-04-26 20:56:30 INFO     ---\n",
      "2020-04-26 20:56:30 INFO     Final dataframe has 4916 lines and 2 columns\n",
      "2020-04-26 20:56:30 INFO     Searching for missing values\n",
      "2020-04-26 20:56:30 INFO     No missing values found\n",
      "2020-04-26 20:56:30 INFO     Writing autoclass.db2 file\n",
      "2020-04-26 20:56:30 INFO     If any, missing values will be encoded as '?'\n",
      "2020-04-26 20:56:30 DEBUG    Writing autoclass.tsv file [for later use]\n",
      "2020-04-26 20:56:30 INFO     Writing .hd2 file\n",
      "2020-04-26 20:56:30 INFO     Writing .model file\n",
      "2020-04-26 20:56:30 INFO     Writing .s-params file\n",
      "2020-04-26 20:56:30 INFO     Writing .r-params file\n",
      "2020-04-26 20:56:30 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 20:56:30 INFO     Writing run file\n",
      "2020-04-26 20:56:30 INFO     AutoClass C executable found in /home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c/autoclass\n",
      "2020-04-26 20:56:30 INFO     AutoClass C version: AUTOCLASS C (version 3.3.6unx)\n",
      "2020-04-26 20:56:30 INFO     Running clustering...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1146 sec."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:15:38 INFO     Extracting autoclass results\n",
      "2020-04-26 21:15:38 INFO     Found 4916 cases classified in 57 classes\n",
      "2020-04-26 21:15:41 INFO     Aggregating input data\n",
      "2020-04-26 21:15:41 INFO     Writing classes + probabilities .tsv file\n",
      "2020-04-26 21:15:42 INFO     Writing .cdt file\n",
      "2020-04-26 21:15:42 ERROR    Unknown format code 'd' for object of type 'float'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/Flow_Durationautoclass_out.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2a5004052773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_class_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dendrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntimeDir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'autoclass_out.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/ProtocolName.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/Flow_Durationautoclass_out.tsv'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import autoclasswrapper as wrapper\n",
    "import os \n",
    "\n",
    "afterall = {}\n",
    "subfeatures = ['Flow_Duration', 'Total_Fwd_Packets']\n",
    "os.environ['PATH'] += \":/home/chuongdv/Documents/SourceCode/MachineLearning/autoclass-c\"\n",
    "!touch /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "!echo \"xref_class_report_att_list = 0, 1 \\nreport_mode = \\\"data\\\" \\ncomment_data_headers_p = true \" >> /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params \n",
    "for feature in subfeatures:\n",
    "    runtimeDir = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/\" + feature\n",
    "    if not Path(runtimeDir).exists():\n",
    "        os.mkdir(runtimeDir)\n",
    "    os.chdir(runtimeDir)\n",
    "    \n",
    "            # Create object to prepare dataset.\n",
    "    clust = wrapper.Input()\n",
    "\n",
    "    # Load datasets from tsv files.\n",
    "    pathData = \"/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/\" + feature + \".tsv\"\n",
    "    clust.add_input_data(pathData, \"real location\")\n",
    "    \n",
    "    # Prepare input data:\n",
    "    # - create a final dataframe\n",
    "    # - merge datasets if multiple inputs\n",
    "    clust.prepare_input_data()\n",
    "\n",
    "    # Create files needed by AutoClass.\n",
    "    clust.create_db2_file()\n",
    "    clust.create_hd2_file()\n",
    "    clust.create_model_file()\n",
    "    clust.create_sparams_file(max_duration = 0)\n",
    "    clust.create_rparams_file()\n",
    "    !rm autoclass.r-params\n",
    "    !cp /home/chuongdv/Documents/SourceCode/MachineLearning/exp/result/autoclass.r-params .\n",
    "    \n",
    "    !rm -f autoclass-run-* *.results-bin\n",
    "\n",
    "\n",
    "    # Search autoclass in path.\n",
    "    wrapper.search_autoclass_in_path()\n",
    "\n",
    "    # Create object to run AutoClass.\n",
    "    run = wrapper.Run()\n",
    "\n",
    "    # Prepare run script.\n",
    "    run.create_run_file()\n",
    "\n",
    "    # Run AutoClass.\n",
    "    run.run()\n",
    "        \n",
    "    timer = 0\n",
    "    step = 2\n",
    "    while not Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        timer += step\n",
    "        sys.stdout.write(\"\\r\")\n",
    "        sys.stdout.write(f\"Time: {timer} sec.\")\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(step)\n",
    "        if Path(\"autoclass-run-failure\").exists():\n",
    "            print(\"error\")\n",
    "            break\n",
    "            \n",
    "    if Path(runtimeDir + \"/autoclass-run-success\").exists():\n",
    "        results = wrapper.Output()\n",
    "        results.extract_results()\n",
    "        results.aggregate_input_data()\n",
    "#         results.write_cdt()\n",
    "#         results.write_cdt(with_proba=True)\n",
    "#         results.write_class_stats()\n",
    "#         results.write_dendrogram()\n",
    "        result = pd.read_csv(runtimeDir + '/autoclass_out.tsv', encoding=\"utf-8\", header=0, sep='\\t', index_col=0)\n",
    "        label =  pd.read_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/ProtocolName.tsv', encoding='utf-8', header=0, sep='\\t', index_col=0)\n",
    "\n",
    "        label['cluster'] = result['main-class']\n",
    "        label.to_csv('app.csv', index = True, header=True)\n",
    "\n",
    "\n",
    "        listH = []\n",
    "        listApp = []\n",
    "        listCluster = []\n",
    "        def fun(x):\n",
    "            listCluster.append(x['cluster'].values[0])\n",
    "            listH.append(x['ProtocolName'].value_counts().max()/x.shape[0])\n",
    "            listApp.append(x['ProtocolName'].value_counts().idxmax())\n",
    "\n",
    "\n",
    "        label.groupby('cluster').apply(fun)\n",
    "\n",
    "        H = sum(listH)/len(listH)\n",
    "        print(listH)\n",
    "        print(listApp)\n",
    "        print(listCluster)\n",
    "        print(H)\n",
    "\n",
    "        dict = {'Cluster': listCluster, 'App': listApp, 'H': listH}\n",
    "\n",
    "        saveResult = pd.DataFrame(dict)\n",
    "\n",
    "        saveResult.to_csv(runtimeDir + '/resultCal.csv', index = True, header=True)\n",
    "        \n",
    "        afterall.update({feature:H})\n",
    "        \n",
    "round1 = pd.DataFrame(afterall)\n",
    "round1.to_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/resl.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11434511434511435, 0.21212121212121213, 0.064343163538874, 0.2364341085271318, 0.06796116504854369, 0.32894736842105265, 0.1572052401746725, 0.19166666666666668, 0.13194444444444445, 0.08396946564885496, 0.22388059701492538, 0.09243697478991597, 0.11811023622047244, 0.272, 0.0673076923076923, 0.0784313725490196, 0.06422018348623854, 0.0967741935483871, 0.14432989690721648, 0.12790697674418605, 0.18309859154929578, 0.21052631578947367, 0.0958904109589041, 0.08823529411764706, 0.15492957746478872, 0.1643835616438356, 0.17543859649122806, 0.1016949152542373, 0.15942028985507245, 0.1038961038961039, 0.11627906976744186, 0.4883720930232558, 0.10526315789473684, 0.25, 0.5714285714285714, 0.09523809523809523, 0.27586206896551724, 0.13333333333333333, 0.2903225806451613, 0.5, 0.5909090909090909, 0.16, 0.3076923076923077, 0.08695652173913043, 0.7777777777777778, 0.631578947368421, 0.125, 1.0, 0.3076923076923077, 0.125, 0.9230769230769231, 0.16666666666666666, 0.2857142857142857, 0.5, 0.4, 0.3333333333333333, 0.3333333333333333]\n",
      "['IP_ICMP', 'NTP', 'HTTP', 'CONTENT_FLASH', 'MS_ONE_DRIVE', 'TEAMVIEWER', 'FTP_DATA', 'DROPBOX', 'UBUNTUONE', 'TELEGRAM', 'EDONKEY', 'CLOUDFLARE', 'SPOTIFY', 'DNS', 'SKYPE', 'HTTP_PROXY', 'INSTAGRAM', 'FACEBOOK', 'HTTP_DOWNLOAD', 'SSL', 'WINDOWS_UPDATE', 'AMAZON', 'TWITTER', 'MICROSOFT', 'TOR', 'WAZE', 'SPOTIFY', 'YAHOO', 'DEEZER', 'MQTT', 'DROPBOX', 'DEEZER', 'MQTT', 'OFFICE_365', 'INSTAGRAM', 'EBAY', 'SSL_NO_CERT', 'FACEBOOK', 'TEAMVIEWER', 'WAZE', 'SSH', 'GMAIL', 'SPOTIFY', 'HTTP', 'CLOUDFLARE', 'WAZE', 'EBAY', 'SSH', 'EBAY', 'MS_ONE_DRIVE', 'WAZE', 'EASYTAXI', 'SKYPE', 'FACEBOOK', 'WHATSAPP', 'HTTP_CONNECT', 'TWITTER']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
      "0.24899438938815618\n"
     ]
    }
   ],
   "source": [
    "        result = pd.read_csv(runtimeDir + '/autoclass_out.tsv', encoding=\"utf-8\", header=0, sep='\\t', index_col=0)\n",
    "        label =  pd.read_csv('/home/chuongdv/Documents/SourceCode/MachineLearning/exp/data/features/ProtocolName.tsv', encoding='utf-8', header=0, sep='\\t', index_col=0)\n",
    "\n",
    "        label['cluster'] = result['main-class']\n",
    "        label.to_csv('app.csv', index = True, header=True)\n",
    "\n",
    "\n",
    "        listH = []\n",
    "        listApp = []\n",
    "        listCluster = []\n",
    "        def fun(x):\n",
    "            listCluster.append(x['cluster'].values[0])\n",
    "            listH.append(x['ProtocolName'].value_counts().max()/x.shape[0])\n",
    "            listApp.append(x['ProtocolName'].value_counts().idxmax())\n",
    "\n",
    "\n",
    "        label.groupby('cluster').apply(fun)\n",
    "\n",
    "        H = sum(listH)/len(listH)\n",
    "        print(listH)\n",
    "        print(listApp)\n",
    "        print(listCluster)\n",
    "        print(H)\n",
    "\n",
    "        dict = {'Cluster': listCluster, 'App': listApp, 'H': listH}\n",
    "\n",
    "        saveResult = pd.DataFrame(dict)\n",
    "\n",
    "        saveResult.to_csv(runtimeDir + 'resultCal.csv', index = True, header=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
